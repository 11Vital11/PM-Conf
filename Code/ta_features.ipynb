{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance >> None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas_ta >> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install alphaVantage-api >> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas-datareader >> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncumulative delta, Adaptive Moving Average, Archer Moving Averages Trends, Awesome Oscillator, Archer On Balance Volume, Archer On Balance Volume, \\nAroon Oscillator, brar, Z Score, Choppiness Index (CHOP), Chande Kroll Stop (CKSP), decay, dema, Directional Movement, Donchian Channels (DC),\\n Fibonacci's Weighted Moving Average (FWMA), hl2, Hull Moving Average (HMA), Holt-Winter Channel and MA, Relative Vigor Index (RVI),\\nJurik Moving Average Average (JMA)!!!!, Keltner Channels (KC), KDJ indicator, Rolling Kurtosis indicator?????,  Klinger Volume Oscillator (KVO),\\nLinear Regression Moving Average, long_run?????, McGinley Dynamic Indicator, Negative Volume Index (NVI), Parabolic Stop and Reverse (SAR), \\nPositive Volume Index (PVI), Percentage Volume Oscillator (PVO), Price Volume Rank, Price-Volume Trend, Relative Strength Xtra,\\nRelative Vigor Index (RVGI), Relative Volatility Index (RVI), Sine Weighted Moving Average (SWMA), SMI Ergodic Indicator (SMI), \\nSqueeze PRO, Ehler's Super Smoother Filter (SSF), Schaff Trend Cycle (STC), Stochastic (STOCHRSI), Supertrend (supertrend),\\nSymmetric Weighted Moving Average (SWMA), Tim Tillson's T3 Moving Average, TD Sequential (TD_SEQ), Triangular Moving Average (TRIMA),\\nTRIX is a momentum oscillator, true_range, TTM Trend (TTM_TRND), Variable Index Dynamic Average (VIDYA), Vortex Two oscillators indicator,\\nVolume Profile (VP), Volume Weighted Average Price, Volume Weighted Moving Average (VWMA), Zero Lag Moving Average (ZLMA), \\n\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import watchlist\n",
    "from matplotlib.pyplot import plot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_around(k, level):\n",
    "  for i in range(int(k * 0.99), int(k * 1.01) + 1):\n",
    "    if i % level == 0:\n",
    "      return 1\n",
    "  return 0\n",
    "\n",
    "def check_integer_level(tpl, level):\n",
    "  for num in tpl:\n",
    "    if check_number_around(num, level) == 1:\n",
    "      return 1\n",
    "  return 0\n",
    "\n",
    "def shift_values(elem, n, tpl):\n",
    "  last = []\n",
    "  for i in range(4):\n",
    "    last += [tpl[i]] + elem[i * n : (i + 1) * n - 1 ]\n",
    "  return last\n",
    "\n",
    "\n",
    "def feature_generation(data, ticker, levels, n_days, index):\n",
    "  #'1993-01-29','2023-11-01'\n",
    "\n",
    "  adder = []\n",
    "  m = 0\n",
    "  \n",
    "  last_prices = [0 for i in range(4 * n_days)]\n",
    "  \n",
    "  \n",
    "\n",
    "  for ind, tpl in enumerate(data.itertuples()):\n",
    "   \n",
    "    if (data.loc[f'{tpl[0]}']['High'] > m):\n",
    "      m = data.loc[f'{tpl[0]}']['High']\n",
    "    adder.append([check_integer_level(tpl[1:5], i) for i in levels] + [tpl[4] / m - 1 ] + [i for i in last_prices])\n",
    "\n",
    "    if (ind < n_days):\n",
    "      last_prices[n_days - ind - 1] = tpl[1]\n",
    "      last_prices[2 * n_days - ind - 1] = tpl[2]\n",
    "      last_prices[3 * n_days - ind - 1] = tpl[3]\n",
    "      last_prices[4 * n_days - ind - 1] = tpl[4]\n",
    "\n",
    "    else:\n",
    "      last_prices = shift_values(last_prices, n_days, tpl[1:5])\n",
    "\n",
    "  \t\t\t\n",
    "  feature_name_last_prices = [f'{ticker} Last Open {i}' for i in range(1, n_days + 1)] + [f'{ticker} Last High {i}' for i in range(1, n_days + 1)] + [f'{ticker} Last Low {i}' for i in range(1, n_days + 1)] + [f'{ticker} Last Close {i}' for i in range(1, n_days + 1)]\n",
    "  int_data = pd.DataFrame(data=np.array(adder), columns=[f'{ticker} level {i}' for i in levels] + [f'{ticker} % from high'] + feature_name_last_prices, index=index)\n",
    "  return int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "here\n",
      "[+] Strategy: All\n",
      "[i] Indicator arguments: {'timed': False, 'append': True}\n",
      "[i] Excluded[12]: above, above_value, below, below_value, cross, cross_value, long_run, short_run, td_seq, tsignals, vp, xsignals\n",
      "[i] Multiprocessing 131 indicators with 3 chunks and 4/4 cpus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:07,  6.85it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"Timedelta\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Python310\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Python310\\lib\\multiprocessing\\pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"c:\\Python310\\lib\\site-packages\\pandas_ta\\core.py\", line 469, in _mp_worker\n    return getattr(self, method)(*args, **kwargs)[0]\n  File \"c:\\Python310\\lib\\site-packages\\pandas_ta\\core.py\", line 1211, in ichimoku\n    result, span = ichimoku(high=high, low=low, close=close, tenkan=tenkan, kijun=kijun, senkou=senkou, include_chikou=include_chikou, offset=offset, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\pandas_ta\\overlap\\ichimoku.py\", line 87, in ichimoku\n    new_dt = date_range(start=last + tdelta, periods=kijun, freq=\"B\")\nTypeError: can only concatenate str (not \"Timedelta\") to str\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m custom_b \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mStrategy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, ta\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m},{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m},\n\u001b[0;32m     18\u001b[0m                                       {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m}, \n\u001b[0;32m     19\u001b[0m                                         ] \u001b[38;5;241m+\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: indicator} \u001b[38;5;28;01mfor\u001b[39;00m indicator \u001b[38;5;129;01min\u001b[39;00m indicators])\n\u001b[0;32m     21\u001b[0m watch\u001b[38;5;241m.\u001b[39mstrategy \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mAllStrategy \u001b[38;5;66;03m#custom_b   ta.AllStrategy # If you have a Custom Strategy, you can use it here.\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mwatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#data = watch.data[ticker]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()]\n",
      "File \u001b[1;32me:\\Наука\\Otus\\ML advanced\\Итоговый проект\\watchlist.py:219\u001b[0m, in \u001b[0;36mWatchlist.load\u001b[1;34m(self, ticker, tf, index, drop, plot, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhere\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug: \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[+] TA[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mta)\u001b[39m}\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 219\u001b[0m     df\u001b[39m.\u001b[39mta\u001b[39m.\u001b[39mstrategy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, timed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimed, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    221\u001b[0m df\u001b[39m.\u001b[39mticker \u001b[39m=\u001b[39m ticker \u001b[39m# Attach ticker to the DataFrame\u001b[39;00m\n\u001b[0;32m    222\u001b[0m df\u001b[39m.\u001b[39mtf \u001b[39m=\u001b[39m tf\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas_ta\\core.py:792\u001b[0m, in \u001b[0;36mAnalysisIndicators.strategy\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_run \u001b[39m=\u001b[39m get_time(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexchange, to_string\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    791\u001b[0m \u001b[39m# Apply prefixes/suffixes and appends indicator results to the  DataFrame\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process(r, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results]\n\u001b[0;32m    794\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m    795\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[i] Total indicators: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ta)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas_ta\\core.py:792\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_run \u001b[39m=\u001b[39m get_time(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexchange, to_string\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    791\u001b[0m \u001b[39m# Apply prefixes/suffixes and appends indicator results to the  DataFrame\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process(r, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m results]\n\u001b[0;32m    794\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m    795\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[i] Total indicators: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ta)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\multiprocessing\\pool.py:420\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    412\u001b[0m result \u001b[39m=\u001b[39m IMapIterator(\u001b[39mself\u001b[39m)\n\u001b[0;32m    413\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_taskqueue\u001b[39m.\u001b[39mput(\n\u001b[0;32m    414\u001b[0m     (\n\u001b[0;32m    415\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_guarded_task_generation(result\u001b[39m.\u001b[39m_job,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m         result\u001b[39m.\u001b[39m_set_length\n\u001b[0;32m    419\u001b[0m     ))\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m (item \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m result \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m chunk)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\multiprocessing\\pool.py:870\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m    869\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m--> 870\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"Timedelta\") to str"
     ]
    }
   ],
   "source": [
    "tickers = ['^VIX', '^IXIC', 'DX-Y.NYB', '^GSPC']\n",
    "\n",
    "tick_levels_dict = {'^GSPC': [25, 50, 100, 200, 250, 500, 1000], '^VIX': [5, 10, 20, 25, 30, 50], 'DX-Y.NYB': [5, 10, 20, 25, 30, 50, 100], '^IXIC': [50, 100, 500, 1000, 2500, 5000, 10000]}\n",
    "\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "  tf = \"D\"\n",
    "  \n",
    "  prices = yf.download(ticker)\n",
    "  prices.to_csv(f\"{ticker}_{tf}.csv\")\n",
    "  \n",
    "  watch = watchlist.Watchlist([ticker], tf=tf, ds_name=\"yahoo\", timed=False)\n",
    "  indicators = ['squeeze', 'aberration', 'accbands', 'adosc', 'adx', 'alma', 'aroon', 'atr', 'bias', 'bop', 'cci', 'cfo', 'cg', 'cmf', 'cmo', 'cti', \n",
    "  'decreasing', 'dpo', 'ebsw', 'efi', 'entropy', \n",
    "  'eom', 'er', 'eri', 'fisher', 'hilo', 'increasing', 'inertia', 'kst', 'macd', 'massi', 'mfi', 'mom', 'natr', 'pgo', 'psar', 'psl', 'roc', 'thermo', 'ttm_trend', 'ui', 'vhf', 'vp' ]\n",
    "  custom_b = ta.Strategy(name=\"B\", ta=[{\"kind\": \"ema\", \"length\": 5},{\"kind\": \"ema\", \"length\": 10}, {\"kind\": \"ema\", \"length\": 20},{\"kind\": \"ema\", \"length\": 50},\n",
    "                                        {\"kind\": \"ema\", \"length\": 100}, {\"kind\": \"ema\", \"length\": 200}, {\"kind\": \"sma\", \"length\": 200}, \n",
    "                                          ] + [{\"kind\": indicator} for indicator in indicators])\n",
    "    \n",
    "  watch.strategy = custom_b   #ta.AllStrategy # If you have a Custom Strategy, you can use it here.\n",
    "  data = watch.load(ticker, verbose=True, )\n",
    "  \n",
    "  \n",
    "  #data = watch.data[ticker]\n",
    "  data.columns = [f'{ticker}_' + name for name in data.columns.values.tolist()]\n",
    "  data = data.drop([f'{ticker}_' + 'low_Close', f'{ticker}_' + 'mean_Close', f'{ticker}_' + 'high_Close', f'{ticker}_' + 'pos_Volume', f'{ticker}_' + 'neg_Volume', f'{ticker}_' + 'total_Volume'], axis=1)\n",
    "  my_features = feature_generation(prices, ticker, tick_levels_dict[ticker], 10, data.index)\n",
    "  data = pd.concat([data, my_features], axis=1)\n",
    "\n",
    " \n",
    "  data = data.loc['1993-01-29':]\n",
    " \n",
    "  data.to_csv(f'{ticker}_ta_my_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7588, 516)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_data, data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mall_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_raw.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:3721\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3710\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3712\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3713\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3714\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3718\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3719\u001b[0m )\n\u001b[1;32m-> 3721\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3722\u001b[0m     path_or_buf,\n\u001b[0;32m   3723\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3724\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3725\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3726\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3727\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3728\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3729\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3730\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3731\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3732\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3733\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3734\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3735\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3736\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3737\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3738\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data_raw.csv'"
     ]
    }
   ],
   "source": [
    "tickers = ['^VIX', '^IXIC', 'DX-Y.NYB']\n",
    "all_data = pd.read_csv('^GSPC_ta_my_features.csv')\n",
    "for ticker in tickers:\n",
    "    data = pd.read_csv(f'{ticker}_ta_my_features.csv')\n",
    "    all_data = pd.concat([all_data, data], axis=1, join='inner')\n",
    "\n",
    "print(all_data.shape)\n",
    "all_data.to_csv('data_raw.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
